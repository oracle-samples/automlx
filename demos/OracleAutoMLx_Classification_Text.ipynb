{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc8bdc14",
   "metadata": {},
   "source": [
    "***\n",
    "# <font color=red>Building and Explaining a Text Classifier using AutoMLx</font>\n",
    "<p style=\"margin-left:10%; margin-right:10%;\">by the <font color=teal> Oracle AutoMLx Team </font></p>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af84a716",
   "metadata": {},
   "source": [
    "AutoMLx Text Classification Demo version 23.4.0.\n",
    "\n",
    "Copyright © 2023, Oracle and/or its affiliates.\n",
    "\n",
    "Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd711c8",
   "metadata": {},
   "source": [
    "## Overview of this Notebook\n",
    "\n",
    "In this notebook we will build a classifier using the Oracle AutoMLx tool for the public 20newsgroup dataset. The dataset is a binary classification dataset, and more details about the dataset can be found at http://qwone.com/~jason/20Newsgroups/.\n",
    "We explore the various options provided by the Oracle AutoMLx tool, allowing the user to exercise control over the AutoML training process. We then evaluate the different models trained by AutoML. Finally we provide an overview of the possibilities that Oracle AutoMLx offers for explaining the predictions of the tuned model.\n",
    "\n",
    "---\n",
    "## Prerequisites\n",
    "\n",
    "  - Experience level: Novice (Python and Machine Learning)\n",
    "  - Professional experience: Some industry experience\n",
    "---\n",
    "\n",
    "## Business Use\n",
    "\n",
    "Data analytics and modeling problems using Machine Learning (ML) are becoming popular and often rely on data science expertise to build accurate ML models. Such modeling tasks differs according to type of problem to be solved, eg. Text classification primarily involve the following steps:\n",
    "- Preprocess dataset (vectorize).\n",
    "- Pick an appropriate model for the given dataset and prediction task at hand.\n",
    "- Tune the chosen model’s hyperparameters for the given dataset.\n",
    "\n",
    "All of these steps are significantly time consuming and heavily rely on data scientist expertise. Unfortunately, to make this problem harder, the best feature subset, model, and hyperparameter choice widely varies with the dataset and the prediction task. Hence, there is no one-size-fits-all solution to achieve reasonably good model performance. Using a simple Python API, AutoML can quickly jump-start the datascience process with an accurately-tuned model and appropriate features for a given prediction task.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- <a href='#setup'>Setup</a>\n",
    "- <a href='#load-data'>Load the 20newsgroup Income dataset</a>\n",
    "- <a href='#AutoML'>AutoML</a>\n",
    "  - <a href='#Engine'>Set the engine</a>\n",
    "  - <a href='#provider'>Create an Instance of Oracle AutoMLx</a>\n",
    "  - <a href='#default'>Train a Model using AutoMLx</a>\n",
    "  - <a href='#analyze'>Analyze the AutoMLX optimization process </a>\n",
    "      - <a href='#algorithm-selection'>Algorithm Selection</a>\n",
    "      - <a href='#adaptive-sampling'>Adaptive Sampling</a>\n",
    "      - <a href='#feature-selection'>Feature Selection</a>\n",
    "      - <a href='#hyperparameter-tuning'>Hyperparameter Tuning</a>\n",
    "  - <a href='#advanced'>Advanced AutoML Configuration</a>\n",
    "- <a href='#MLX'>Machine Learning Explainability (MLX)</a>\n",
    "  - <a href='#MLX-initialization'>Initialize an MLExplainer</a>\n",
    "  - <a href='#MLX-global'>Global Token Importance</a>\n",
    "  - <a href='#MLX-local'>Local Token Importance</a>\n",
    "- <a href='#ref'>References</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34247d36",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "## Setup\n",
    "\n",
    "Basic setup for the Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef44d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea79308",
   "metadata": {},
   "source": [
    "Load the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7866c172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Settings for plots\n",
    "plt.rcParams['figure.figsize'] = [10, 7]\n",
    "plt.rcParams['font.size'] = 15\n",
    "\n",
    "import automlx\n",
    "from automlx import init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023e0925",
   "metadata": {},
   "source": [
    "<a id='load-data'></a>\n",
    "## Load the 20 News Group dataset\n",
    "We start by reading in the dataset from sklearn. The dataset has already been pre-split into training and test sets. The training set will be used to create a Machine Learning model using AutoMLx, and the test set will be used to evaluate the model's performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19311a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = fetch_20newsgroups(subset='train')\n",
    "test = fetch_20newsgroups(subset='test')\n",
    "\n",
    "target_names = train.target_names\n",
    "\n",
    "X_train, y_train = pd.DataFrame(train.data), pd.DataFrame(train.target)\n",
    "X_test, y_test = pd.DataFrame(test.data), pd.DataFrame(test.target)\n",
    "\n",
    "column_names = [\"Message\"]\n",
    "X_train.columns = column_names\n",
    "X_test.columns = column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac264a4",
   "metadata": {},
   "source": [
    "Lets look at a few of the values in the data. 20 NewsGroup is a classification dataset made of text samples. Each sample has an associated class (also called topic), which can be one of the followings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8b6852",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d7663e",
   "metadata": {},
   "source": [
    "We display some examples of data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c7feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f204c1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebf479a",
   "metadata": {},
   "source": [
    "We further downsample the train set to have a reasonable training time for this demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b043c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, _, y_train, _ = train_test_split(X_train, y_train,\n",
    "                                          test_size=0.7,\n",
    "                                          stratify=y_train,\n",
    "                                          random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b298bf",
   "metadata": {},
   "source": [
    "Finally we generate a validation set and only use that for internal pipeline validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad769256",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train,\n",
    "                                                      test_size=0.2,\n",
    "                                                      stratify=y_train,\n",
    "                                                      random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be588acf",
   "metadata": {},
   "source": [
    "<a id='AutoML'></a>\n",
    "## AutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4050c6",
   "metadata": {},
   "source": [
    "<a id='Engine'></a>\n",
    "### Setting the execution engine\n",
    "The AutoML package offers the function `init`, which allows to initialize the parallelization engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201c8568",
   "metadata": {},
   "outputs": [],
   "source": [
    "init(engine='ray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a181f18",
   "metadata": {},
   "source": [
    "<a id='provider'></a>\n",
    "### Create an instance of Oracle AutoMLx\n",
    "\n",
    "The Oracle AutoMLx solution provides a pipeline that automatically finds a tuned model given a prediction task and a training dataset. In particular it allows to find a tuned model for any supervised prediction task, for example: classification or regression where the target can be binary, categorical or real-valued.\n",
    "\n",
    "AutoML consists of five main steps:\n",
    "- **Preprocessing** (Feature extraction and selection) : The pipeline extracts tabular features using [TFIDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) that it then selects between.\n",
    "- **Algorithm Selection** : Identify the right classification algorithm for a given dataset, choosing from amongst:\n",
    "   - AdaBoostClassifier\n",
    "   - CatBoostClassifier\n",
    "   - DecisionTreeClassifier\n",
    "   - ExtraTreesClassifier\n",
    "   - TorchMLPClassifier\n",
    "   - KNeighborsClassifier\n",
    "   - LGBMClassifier\n",
    "   - LinearSVC\n",
    "   - LogisticRegression\n",
    "   - RandomForestClassifier\n",
    "   - SVC\n",
    "   - XGBClassifier\n",
    "   - GaussianNB\n",
    "   - TabNetClassifier\n",
    "- **Adaptive Sampling** : Select a subset of the data samples for the model to be trained on.\n",
    "- **Feature Selection** : Select a subset of the features (extracted with TFIDF), based on the previously selected model. In the rest of this notebook, we will implicitly refer to the extracted features as data features.\n",
    "- **Hyperparameter Tuning** : Find the right model parameters that maximize score for the given dataset.\n",
    "\n",
    "All these pieces are readily combined into a simple AutoMLx pipeline which automates the entire Machine Learning process with minimal user input/interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b331dd4",
   "metadata": {},
   "source": [
    "<a id='default'></a>\n",
    "### Train a model using AutoMLx\n",
    "\n",
    "The AutoMLx API is quite simple to work with. We create an instance of the pipeline. Next, the training data is passed to the `fit()` function which executes the four previously mentioned steps.\n",
    "\n",
    "A model is then generated and can be used for prediction tasks. We use the roc_auc scoring metric to evaluate the performance of this model on unseen data (`X_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f362f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "est1 = automlx.Pipeline(task='classification')\n",
    "est1.fit(X_train, y_train, X_valid, y_valid, col_types=['text'])\n",
    "\n",
    "y_predict = est1.predict(X_test)\n",
    "score_default = f1_score(y_test, y_predict, average=\"micro\")\n",
    "\n",
    "print('F1 Micro Score on test data: {:3.3f}'.format(score_default))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425bab22",
   "metadata": {},
   "source": [
    "<a id='analyze'></a>\n",
    "### Analyze the AutoMLx optimization process\n",
    "\n",
    "During the AutoML process, a summary of the optimization process is logged. It consists of:\n",
    "- Information about the training data\n",
    "- Information about the AutoMLx Pipeline, such as:\n",
    "    - selected features that AutoMLx found to be most predictive in the training data;\n",
    "    - selected algorithm that was the best choice for this data;\n",
    "    - hyperparameters for the selected algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dfdf93",
   "metadata": {},
   "source": [
    "AutoMLx provides a print_summary API to output all the different trials performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d702f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "est1.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c59aca",
   "metadata": {},
   "source": [
    "We also provide the capability to visualize the results of each stage of the AutoMLx pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7452f56",
   "metadata": {},
   "source": [
    "<a id='algorithm-selection'></a>\n",
    "#### Algorithm Selection\n",
    "\n",
    "The plot below shows the scores predicted by Algorithm Selection for each algorithm. The horizontal line shows the average score across all algorithms. Algorithms below the line are colored turquoise, whereas those with a score higher than the mean are colored teal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5ba14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each trial is a row in a dataframe that contains\n",
    "# Algorithm, Number of Samples, Number of Features, Hyperparameters, Score, Runtime, Memory Usage, Step as features\n",
    "trials = est1.completed_trials_summary_[est1.completed_trials_summary_[\"Step\"].str.contains('Model Selection')]\n",
    "name_of_score_column = f\"Score ({est1._inferred_score_metric[0].name})\"\n",
    "trials.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "trials.dropna(subset=[name_of_score_column], inplace = True)\n",
    "scores = trials[name_of_score_column].tolist()\n",
    "models = trials['Algorithm'].tolist()\n",
    "colors = []\n",
    "\n",
    "y_margin = 0.10 * (max(scores) - min(scores))\n",
    "s = pd.Series(scores, index=models).sort_values(ascending=False)\n",
    "s = s.dropna()\n",
    "for f in s.keys():\n",
    "    if f.strip()  ==  est1.selected_model_.strip():\n",
    "        colors.append('orange')\n",
    "    elif s[f] >= s.mean():\n",
    "        colors.append('teal')\n",
    "    else:\n",
    "        colors.append('turquoise')\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.set_title(\"Algorithm Selection Trials\")\n",
    "ax.set_ylim(min(scores) - y_margin, max(scores) + y_margin)\n",
    "ax.set_ylabel(est1._inferred_score_metric[0].name)\n",
    "s.plot.bar(ax=ax, color=colors, edgecolor='black')\n",
    "ax.axhline(y=s.mean(), color='black', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be6e1c6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "<a id='feature-selection'></a>\n",
    "#### Feature Selection\n",
    "After finding a sample subset, the next step is to find a relevant feature subset to maximize score for the chosen algorithm. The feature selection step identifies the smallest feature subset that does not compromise on the score of the chosen algorithm. The orange line shows the optimal number of features chosen by Feature Selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c624e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each trial is a row in a dataframe that contains\n",
    "# Algorithm, Number of Samples, Number of Features, Hyperparameters, Score, Runtime, Memory Usage, Step as features\n",
    "trials = est1.completed_trials_summary_[est1.completed_trials_summary_[\"Step\"].str.contains('Feature Selection')]\n",
    "trials.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "trials.dropna(subset=[name_of_score_column], inplace = True)\n",
    "trials.sort_values(by=['# Features'],ascending=True, inplace = True)\n",
    "scores = trials[name_of_score_column].tolist()\n",
    "n_features = trials['# Features'].tolist()\n",
    "\n",
    "y_margin = 0.10 * (max(scores) - min(scores))\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.set_title(\"Feature Selection Trials\")\n",
    "ax.set_xlabel(\"Number of Features\")\n",
    "ax.set_ylabel(est1._inferred_score_metric[0].name)\n",
    "ax.grid(color='g', linestyle='-', linewidth=0.1)\n",
    "ax.set_ylim(min(scores) - y_margin, max(scores) + y_margin)\n",
    "ax.plot(n_features, scores, 'k:', marker=\"s\", color='teal', markersize=3)\n",
    "ax.axvline(x=len(est1.selected_features_names_), color='orange', linewidth=2.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844127ee",
   "metadata": {},
   "source": [
    "<a id='hyperparameter-tuning'></a>\n",
    "#### Hyperparameter Tuning\n",
    "\n",
    "Hyperparameter Tuning is the last stage of the AutoMLx pipeline, and focuses on improving the chosen algorithm's score on the reduced dataset (after Adaptive Sampling and Feature Selection). We use a novel algorithm to search across many hyperparameters dimensions, and converge automatically when optimal hyperparameters are identified. Each trial in the graph below represents a particular hyperparameters configuration for the selected model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9466eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each trial is a row in a dataframe that contains\n",
    "# Algorithm, Number of Samples, Number of Features, Hyperparameters, Score, Runtime, Memory Usage, Step as features\n",
    "trials = est1.completed_trials_summary_[est1.completed_trials_summary_[\"Step\"].str.contains('Model Tuning')]\n",
    "trials.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "trials.dropna(subset=[name_of_score_column], inplace = True)\n",
    "trials.drop(trials[trials['Finished'] == -1].index, inplace = True)\n",
    "trials['Finished']= trials['Finished'].apply(lambda x: time.mktime(datetime.datetime.strptime(x,\n",
    "                                             \"%a %b %d %H:%M:%S %Y\").timetuple()))\n",
    "trials.sort_values(by=['Finished'],ascending=True, inplace = True)\n",
    "scores = trials[name_of_score_column].tolist()\n",
    "score = []\n",
    "score.append(scores[0])\n",
    "for i in range(1,len(scores)):\n",
    "    if scores[i]>= score[i-1]:\n",
    "        score.append(scores[i])\n",
    "    else:\n",
    "        score.append(score[i-1])\n",
    "y_margin = 0.10 * (max(score) - min(score))\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.set_title(\"Hyperparameter Tuning Trials\")\n",
    "ax.set_xlabel(\"Iteration $n$\")\n",
    "ax.set_ylabel(est1._inferred_score_metric[0].name)\n",
    "ax.grid(color='g', linestyle='-', linewidth=0.1)\n",
    "ax.set_ylim(min(score) - y_margin, max(score) + y_margin)\n",
    "ax.plot(range(1, len(trials) + 1), score, 'k:', marker=\"s\", color='teal', markersize=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90505fef",
   "metadata": {},
   "source": [
    "<a id='advanced'></a>\n",
    "### Advanced AutoML Configuration\n",
    "\n",
    "You can also configure the pipeline with suitable parameters according to your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b551229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_pipeline = automlx.Pipeline(\n",
    "    task='classification',\n",
    "    model_list=[                 # Specify the models you want the AutoML to consider\n",
    "        'GaussianNB',\n",
    "        'LGBMClassifier',\n",
    "],\n",
    "    min_features=1.0,            # Specify minimum features to force the model to use. It can take 3 possible types of values:\n",
    "                                 # If int, 0 < min_features <= n_features,\n",
    "                                 # If float, 0 < min_features <= 1.0, 1.0 means disabling feature selection\n",
    "                                 # If list, names of features to keep, for example ['a', 'b'] means keep features 'a' and 'b'\n",
    "\n",
    "    n_algos_tuned=2,             # Choose how many models to tune\n",
    "    adaptive_sampling=False,     # Disable or enable Adaptive Sampling step. Default to `True`\n",
    "    preprocessing=True,          # Disable or enable Preprocessing step. Default to `True`\n",
    "    search_space={},             # You can specify the hyper-parameters and ranges AutoML searches\n",
    "    max_tuning_trials=2,         # The maximum number of tuning trials. Can be integer or Dict (max number for each model)\n",
    "    score_metric='f1_macro',     # Any scikit-learn metric or a custom function\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29df2a57",
   "metadata": {},
   "source": [
    "A few of the advanced settings can be passed directly to the pipeline's fit method, instead of its constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03924518",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_pipeline.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_valid,\n",
    "    y_valid,\n",
    "    col_types=[\"text\"],\n",
    "    time_budget= 50,    # Specify time budget in seconds\n",
    "    cv='auto'           # Automatically pick a good cross-validation (cv) strategy for the user's dataset.\n",
    "                        # Ignored if X_valid and y_valid are provided.\n",
    "                        # Can also be:\n",
    "                        #   - An integer (for example, to use 5-fold cross validation)\n",
    "                        #   - A list of data indices to use as splits (for advanced, such as time-based splitting)\n",
    ")\n",
    "y_proba = custom_pipeline.predict_proba(X_test)\n",
    "score_default = f1_score(y_test, y_predict, average=\"micro\")\n",
    "\n",
    "print(f'Score on test data : {score_default}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb50f245",
   "metadata": {},
   "source": [
    "<a id='MLX'></a>\n",
    "## Machine Learning Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da152b5",
   "metadata": {},
   "source": [
    "For a variety of decision-making tasks, getting only a prediction as model output is not sufficient. A user may wish to know why the model outputs that prediction, or which data features are relevant for that prediction. For that purpose the Oracle AutoMLx solution defines the MLExplainer object, which allows to compute a variety of model explanations\n",
    "\n",
    "<a id='MLX-initializing'></a>\n",
    "### Initializing an MLExplainer\n",
    "\n",
    "The MLExplainer object takes as argument the trained model, the training data and labels, as well as the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f87eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = automlx.MLExplainer(est1,\n",
    "                              X_train,\n",
    "                              y_train,\n",
    "                              target_names=target_names,\n",
    "                              task=\"classification\",\n",
    "                              col_types=[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ab07a3",
   "metadata": {},
   "source": [
    "<a id='MLX-global'></a>\n",
    "### Model Explanations (Global Token Importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6afe131",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "For text classification tasks, since we first extract tokens (features), the Oracle AutoMLx solution offers a single way to compute a notion of token importance: Global Token Importance. The notion of Global Token Importance intuitively measures how much a token impacts the model's predictions (relative to the provided train labels). Tokens are the most fine-grained building blocks of the NLP model, such as sentences, words, or characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b376803",
   "metadata": {},
   "source": [
    "#### Computing the importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97e29db",
   "metadata": {},
   "source": [
    "We use a permutation-based method to successively measure the importance of each token (feature). Such a method therefore runs in linear time with respect to the\n",
    "number of features (tokens) in the dataset.\n",
    "\n",
    "The method `explain_model()` allows to compute such feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983adf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_explain_model_default = explainer.explain_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acafec8",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b258d42a",
   "metadata": {},
   "source": [
    "There are two options to show the explanation's results:\n",
    "- `to_dataframe()` will return a dataframe of the results.\n",
    "- `show_in_notebook()` will show the results as a bar plot.\n",
    "\n",
    "The features are returned in decreasing order of importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6c91ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_explain_model_default.to_dataframe(n_tokens=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d8cf97",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "result_explain_model_default.show_in_notebook(n_tokens=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a37e375",
   "metadata": {},
   "source": [
    "<a id='MLX-local'></a>\n",
    "## Local Token importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6145f5",
   "metadata": {},
   "source": [
    "For text classification tasks, since we first extract tokens (features), the Oracle AutoMLx solution offers a single way to compute a notion of token importance: Local Token Importance. The notion of Local Token Importance intuitively measures how much a token impacts an instance's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf5090e",
   "metadata": {},
   "source": [
    "#### Compute the importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f53e83",
   "metadata": {},
   "source": [
    "By default we use a surrogate method to successively measure the importance of each token in a given instance. Such a method therefore runs in linear time with respect to the number of features in the dataset.\n",
    "\n",
    "The method `explain_prediction()` allows to compute such feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb9f884",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "result_explain_prediction_default = explainer.explain_prediction(X_train.iloc[index:index + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b6b014",
   "metadata": {},
   "source": [
    "There are two options to show the explanation's results:\n",
    " - `to_dataframe()` will return a dataframe of the results.\n",
    " - `show_in_notebook()` will show the results as a bar plot.\n",
    "\n",
    "The features are returned in decreasing order of importance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d337eb01",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e559974",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_explain_prediction_default[0].to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcc2bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_explain_prediction_default[0].show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9969fb",
   "metadata": {},
   "source": [
    "<a id='ref'></a>\n",
    "## References\n",
    "* Oracle AutoML http://www.vldb.org/pvldb/vol13/p3166-yakovlev.pdf\n",
    "* scikit-learn https://scikit-learn.org/stable/\n",
    "* Interpretable Machine Learning https://christophm.github.io/interpretable-ml-book/\n",
    "* LIME https://arxiv.org/pdf/1602.04938\n",
    "* 20newsgroup http://qwone.com/~jason/20Newsgroups/"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
